<h1 align="center">"Who is Responsible? The Data, Models, Users or Regulations? Responsible Generative AI for a Sustainable Future"</h1>
<div align=center><img src="rai-cover-refined.svg" width="90%"/></div>

## üåü Overview
Welcome to the official repository for our Responsible AI survey paper. Here you will a list of comprehensive latest papers for Responsible AI domain

## What is Responsible AI?
Responsible Artificial Intelligence (RAI) encompasses the principles, practices, and frameworks governing the design, deployment, and operation of AI systems to ensure they function in accordance with ethical standards, maintain transparency in their decision-making processes, demonstrate clear accountability mechanisms, and fundamentally align with societal values and human welfare objectives.


<div align=center><img src="image2.PNG" width="90%"/></div>



This repository provides an overview of RAI papers in the following areas:
- **Explainable AI [XAI]**
- **Ethical Considerations**
- **Sector Application**
- **Advanced Models**
- **Safety**
- **Privacy and Security**
- **Regularity and Frameworks**

## 1. Existing RAI Surveys
- [2024] **Evaluating privacy, security, and trust perceptions in conversational AI: A systematic review** *A Leschanowsky, S Rech, B Popp, T B√§ckstr√∂m* [[paper](https://www.sciencedirect.com/science/article/pii/S0747563224002127)]
- [2024] **Fairness in Machine Learning: A Survey.** *Simon Caton and Christian Haas* [[paper](https://dl.acm.org/doi/10.1145/3616865)]
- [2024/10] **Responsible AI in the Global Context: Maturity Model and Survey** *Anka Reuel,Patrick Connolly* [[paper](https://arxiv.org/pdf/2410.09985)]
- [2024/4] **Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering** *Qinghua Lu, Liming Zhu* [[paper](https://dl.acm.org/doi/full/10.1145/3626234)]
- [2024/2] **Toward Responsible Artificial Intelligence in Long-Term Care: A Scoping Review on Practical Approaches** *Dirk R M Lukkien, MSc, Henk Herman Nap, PhD* [[paper](https://academic.oup.com/gerontologist/article/63/1/155/6454353)]
- [2023/10] **Responsible AI (RAI) Games and Ensembles** *Yash Gupta, Runtian Zhai, Arun Suggala, Pradeep Ravikumar* [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/e6057bf047bcc5f86ebf4e8db6e24a1f-Abstract-Conference.html)]

## 2. RAI Papers
- **Ethical Challenges and Solutions of Generative AI: An Interdisciplinary Perspective** * Mousa Al-kfairy ,Dheya Mustafa*[[paper](https://arxiv.org/pdf/2410.09985)]
- **Focus! Rating XAI Methods and Finding Biases** *Anna Arias-Duart, Ferran Par√©s*[[paper](https://ieeexplore.ieee.org/abstract/document/9882821)]
- **Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI** *Alejandro Barredo Arrieta, Natalia D√≠az-Rodr√≠guez*[[paper](https://www.sciencedirect.com/science/article/abs/pii/S1566253519308103)]
- **A Review on Explainable Artificial Intelligence for Healthcare: Why, How, and When?** * Subrato Bharati, M. Rubaiyat Hossain Mondal*[[paper](https://arxiv.org/abs/2304.04780)]
- **Fairness in Machine Learning: A Survey** *Simon Caton, Christian Haas*[[paper](https://dl.acm.org/doi/10.1145/3616865)]
- **Efficient data representation by selecting prototypes with importance weights** *Gurumoorthy, K. S., Dhurandhar*[[paper](https://arxiv.org/abs/1707.01212)]
- **TED: Teaching AI to explain its decisions** *Hind, M., Wei, D., Campbell*[[paper](https://doi.org/10.1145/3306618.3314273)]
- **A unified approach to interpreting model predictions** *Lundberg, S. M., & Lee*[[paper](https://github.com/slundberg/shap)]
- **Leveraging latent features for local explanations** *Luss, R., Chen, P. Y*[[paper](https://arxiv.org/abs/1905.12698)]
- **Contrastive Explanations Method with Monotonic Attribute Functions** *Luss et al*[[paper](https://arxiv.org/abs/1905.12698)]
- **Boolean Decision Rules via Column Generation** *Dash et al*[[paper](https://papers.nips.cc/paper/7716-boolean-decision-rules-via-column-generation)]
- **Socially Responsible AI Algorithms: Issues, Purposes, and Challenges** *L Cheng, KR Varshney*[[paper](https://www.jair.org/index.php/jair/article/view/12814)]
- **Explainable AI (XAI): Core ideas, techniques, and solutions** *R Dwivedi, D Dave*[[paper](https://dl.acm.org/doi/abs/10.1145/3561048)]
- **Ethical Challenges and Solutions of Generative AI: An Interdisciplinary Perspective** *Mousa Al-kfairy, Dheya Mustafa* [[paper](https://arxiv.org/pdf/2410.09985)]
- **Data cards: Purposeful and transparent dataset documentation for responsible AI** *Pushkarna, M., Zaldivar, A., & Kjartansson, O.* [[paper](https://dl.acm.org/doi/10.1145/3531146.3533231)]
- **Healthsheet: Development of a transparency artifact for health datasets** *Rostamzadeh, N., Mincu, D., Roy, S., Smart, A., Wilcox, L., Pushkarna, M., & Heller, K.* [[paper](https://arxiv.org/abs/2202.13028)]
- **Fairness through Experimentation: Inequality in A/B testing as an approach to responsible design** *Saint-Jacques, G., Sepehri, A., Li, N., & Perisic, I.* [[paper](https://arxiv.org/pdf/2002.05819)]
- **The energy and carbon footprint of training end-to-end speech recognizers** *Parcollet, T., & Ravanelli, M.* [[paper](https://hal.archives-ouvertes.fr/hal-03190119/document)]
- **Carbon emissions and large neural network training** *Patterson, D., Gonzalez, J., Le, Q., Liang, C., Munguia, L.M., Rothchild, D., So, D., Texier, M., and Dean, J.* [[paper](https://arxiv.org/abs/2104.10350)]
- **Hidden technical debt in machine learning systems** *Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D. & Dennison, D.* [[paper](https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)]
- **Machine learning: The high interest credit card of technical debt** *Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D., & Young, M.* [[paper](https://research.google/pubs/pub43146/)]
- **Energy and policy considerations for deep learning in NLP** *Strubell, E., Ganesh, A., & McCallum, A.* [[paper](https://arxiv.org/abs/1906.02243)]
- **Sustainable AI: AI for sustainability and the sustainability of AI** *van Wynsberghe, A.* [[paper](https://link.springer.com/article/10.1007/s43681-021-00043-6)]
- **Green Algorithms: Quantifying the carbon emissions of computation** *Lannelongue, L. et al.* [[paper](https://arxiv.org/abs/2007.07610)]
- **Trust in Machine Learning** *Varshney, K.* [[paper](https://www.manning.com/books/trust-in-machine-learning)]
- **Interpretable AI** *Thampi, A.* [[paper](https://www.manning.com/books/interpretable-ai)] 
- **AI Fairness** *Mahoney, T., Varshney, K.R., Hind, M.* [[paper](https://learning.oreilly.com/library/view/ai-fairness/9781492077664/)] 
- **Practical Fairness** *Nielsen, A.* [[paper](https://learning.oreilly.com/library/view/practical-fairness/9781492075721/)]
- **Hands-On Explainable AI (XAI) with Python** *Rothman, D.* [[paper](https://www.packtpub.com/product/hands-on-explainable-ai-xai-with-python/9781800208131)] 
- **AI and the Law** *Kilroy, K.* [[paper](https://learning.oreilly.com/library/view/ai-and-the/9781492091837/)]
- **Responsible Machine Learning** *Hall, P., Gill, N., Cox, B.* [[paper](https://learning.oreilly.com/library/view/responsible-machine-learning/9781492090878/)] 
- **Privacy-Preserving Machine Learning** [[paper](https://www.manning.com/books/privacy-preserving-machine-learning)]
- **Human-In-The-Loop Machine Learning: Active Learning and Annotation for Human-Centered AI** [[paper](https://www.manning.com/books/human-in-the-loop-machine-learning)]
- **Interpretable Machine Learning With Python: Learn to Build Interpretable High-Performance Models With Hands-On Real-World Examples** [[paper](https://www.packtpub.com/product/interpretable-machine-learning-with-python/9781800203907)]
- **Responsible AI** *Hall, P., Chowdhury, R.* [[paper](https://learning.oreilly.com/library/view/responsible-ai/9781098102425/)]
- **Quantifying the carbon emissions of machine learning** *Lacoste, A., Luccioni, A., Schmidt, V., & Dandres, T.* [[paper](https://arxiv.org/abs/1910.09700)]
- **Making AI Less ‚ÄúThirsty‚Äù: Uncovering and Addressing the Secret Water Footprint of AI Models** *Li, P., Yang, J., Islam, M. A., & Ren, S.* [[paper](https://arxiv.org/pdf/2304.03271)]
- **The energy and carbon footprint of training end-to-end speech recognizers** *Parcollet, T., & Ravanelli, M.* [[paper](https://hal.archives-ouvertes.fr/hal-03190119/document)]
- **Carbon emissions and large neural network training** *Patterson, D., Gonzalez, J., Le, Q., Liang, C., Munguia, L.M., Rothchild, D., So, D., Texier, M., & Dean, J.* [[paper](https://arxiv.org/abs/2104.10350)]
- **Hidden technical debt in machine learning systems** *Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D.,& Dennison, D.* [[paper](https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)] 
- **Machine learning: The high interest credit card of technical debt** *Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D.,& Young, M.* [[paper](https://research.google/pubs/pub43146/)] 
- **Energy and policy considerations for deep learning in NLP** *Strubell, E., Ganesh, A., & McCallum, A.* [[paper](https://arxiv.org/abs/1906.02243)]
- **Sustainable AI: AI for sustainability and the sustainability of AI** *van Wynsberghe, A.* [[paper](https://link.springer.com/article/10.1007/s43681-021-00043-6)]
- **Green Algorithms: Quantifying the carbon emissions of computation** *Lannelongue, L. et al* [[paper](https://arxiv.org/abs/2007.07610)]
- **Sustainable AI: Environmental implications, challenges, and opportunities** *Wu, C.-J., Raghavendra, R., Gupta, U., Acun, B., Ardalani, N., Maeng, K., Chang, G., Aga, F., Huang, J., Bai, C., Gschwind, M., Gupta, A., Ott, M., Melnikov, A., Candido, S., Brooks, D., Chauhan, G., Lee, B., Lee, H.-H., & Hazelwood, K.* [[paper](https://proceedings.mlsys.org/paper_files/paper/2022/file/462211f67c7d858f663355eff93b745e-Paper.pdf)]
- **A Survey on Knowledge Graphs: Representation, Acquisition, and Applications** *IEEE Transactions on Neural Networks and Learning Systems* [[paper](summaries/explainability/knowlege_graphs_survey.md)]
- **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models** *NeurIPS* [[paper](summaries/explainability/CoT.md)]
- **A Nutritional Label for Rankings** *SIGMOD‚Äô18* [[paper](summaries/explainability/Nutritional_Label.md)]
- **Graph of Thoughts: Solving Elaborate Problems with Large Language Models** *arXiv, 2024* [[paper](summaries/explainability/GoT.md)]
- **Tree of Thoughts: Deliberate Problem Solving with Large Language Models** *NeurIPS* [[paper](summaries/explainability/ToT.md)]
- **Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models** *ICML 2024* [[paper](summaries/explainability/Patchscopes.md)]
- **A Unified Approach to Interpreting Model Predictions** *NIPS 2017* [[paper](summaries/explainability/SHAP.md)]
- **Sparse Autoencoders Find Highly Interpretable Features in Language Models** *arXiv, 2023* [[paper](summaries/explainability/SAE-interpret.md)]
- **Why Should I Trust You? Explaining the Predictions of Any Classifier** *KDD 2016* [[paper](summaries/explainability/LIME.md)]
- **Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation** *ICML 2024* [[paper](summaries/explainability/LLM_random_walk.md)]
- **Evolving Generative AI: Entangling the Accountability Relationship** *Marc T.J Elliott, Deepak P* [[paper](https://dl.acm.org/doi/abs/10.1145/3664823)]
- **Ted-spad: Temporal distinctiveness for self-supervised privacy-preservation for video anomaly detection** *J Fioresi, IR Dave, M Shah* [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.html)]
- **FAIR Enough: Develop and Assess a FAIR-Compliant Dataset for Large Language Model Training?** *S Raza, S Ghuge, C Ding, E Dolatabadi, D Pandya* [[paper](https://direct.mit.edu/dint/article/6/2/559/123375)]  
- **Exploring Memorization and Copyright Violation in Frontier LLMs: A Study of the New York Times v. OpenAI 2023 Lawsuit** *J Freeman, C Rippe, E Debenedetti, M Andriushchenko* [[paper](https://openreview.net/forum?id=C66DBl9At8)]
- **Generative AI in Creative Practice: ML-Artist Folk Theories of T2I Use, Harm, and Harm-Reduction** *Renee Shelby,Shalaleh Rismani,Negar Rostamzadeh* [[paper](https://dl.acm.org/doi/full/10.1145/3613904.3642461)]



## 3. Datasets
- **AI Risk Database** [[Link](https://airisk.io/)] 
- **AI Risk Repository** [[Link](https://airisk.mit.edu)] 
- **ARC AGI** [[Link](https://github.com/fchollet/ARC-AGI)]
- **Common Corpus** [[Link](https://huggingface.co/collections/PleIAs/common-corpus-65d46e3ea3980fdcd66a5613)]
- **An ImageNet replacement for self-supervised pretraining without humans** [[Link](https://www.robots.ox.ac.uk/~vgg/research/pass/)]
- **Huggingface Data Sets** [[Link](https://huggingface.co/datasets)]
- **The Stack** [[Link](https://www.bigcode-project.org/docs/about/the-stack/)]

## 4. Applications
- üìöEducation
- üåçEnvironmental Stability
- üë•Society
- ‚öñÔ∏èPolictics 
- ü©∫Healthcare
- üí∞Finance
- üõ°Ô∏èDefense
- üé®Arts and Entertainment

## 5. Contributing Authors
- SHAINA RAZA‚àó, Vector Institute, Canada
- RIZWAN QURESHI‚àó, Center for Research in Computer Vision, The University of Central Florida, USA
- ANAM ZAHID, Department of Computer Science, Information Technology University of the Punjab, Pakistan
- JOE FIORESI, Center for Research in Computer Vision, The University of Central Florida, USA
- FERHAT SADAK, Department of Mechanical Engineering, Bartin University, T√ºrkiye
- MUHAMMAED SAEED, Saarland University, Germany
- RANJAN SAPKOTA, Washington State University, USA
- ADITYA JAIN, University of Texas at Austin, USA
- ANAS ZAFAR, Fast School of Computing, National University of Computer and Emerging Sciences, Pakistan
- MUNEEB UL HASSAN, School of Information Technology, Deakin University, Australia
- AIZAN ZAFAR, Center for research in computer vision, University of Central FLorida, USA
- HASAN MAQBOOL, Independent Researcher, USA
- ASHMAL VAYANI, Center for Research in Computer Vision, University of Central Florida, USA
- JIA WU, MD Anderson Cancer Center, The University of Texas, USA
- MAGED SHOMAN, University of Tennessee; Oak Ridge National Lab, USA

*Equal contributors


