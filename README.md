# "Who is Responsible? The Data, Models, Users or Regulations? A Comprehensive Survey on Responsible Generative AI for a Sustainable Future" 

<div align=center><img src="rai-cover-refined.svg" width="90%"/></div>

## üåü Overview
[Who is Responsible? The Data, Models, Users or Regulations? Responsible Generative AI for a Sustainable Future](https://www.techrxiv.org/doi/full/10.36227/techrxiv.173834932.29831105/v1)

Welcome to the our Responsible AI survey paper repository. This extensive collection includes papers and developments in the Responsible AI domain, documenting the field's evolution from foundational concepts to implemented regulatory frameworks.

## What is Responsible AI?
Responsible Artificial Intelligence (RAI) encompasses the principles, practices, and frameworks governing the design, deployment, and operation of AI systems to ensure they function in accordance with ethical standards, maintain transparency in their decision-making processes, demonstrate clear accountability mechanisms, and fundamentally align with societal values and human welfare objectives.

<div align=center><img src="image2.PNG" width="90%"/></div>

## üìä Evolution Summary (2020-2025)

**Key Trends Across the Period:**
- **Research Growth**: RAI papers at leading AI conferences increased by 28.8% from 2023 to 2024 alone (992 to 1,278 papers)
- **Industry Adoption**: AI usage in organizations grew from 55% (early 2023) to 78% (2024)
- **Regulatory Maturation**: Evolution from voluntary guidelines (2020) to mandatory frameworks like the EU AI Act (2024)
- **Environmental Awareness**: Major tech companies reporting 29-48% emission increases due to AI workloads
- **Technical Advances**: From basic interpretability to sophisticated reasoning methods and human-validated approaches

This repository provides comprehensive coverage across:
- **Explainable AI [XAI]** - Evolution from foundational concepts to human-validated methods
- **Ethical Considerations & Bias Mitigation** - From awareness to systematic auditing frameworks
- **AI Governance & Regulatory Frameworks** - From proposals to implemented legislation
- **Environmental Sustainability** - From early concerns to comprehensive impact studies
- **Sector Applications** - Across healthcare, finance, education, and beyond
- **Advanced Models & Safety** - Foundation models and generative AI governance
- **Privacy and Security** - Evolution of privacy-preserving techniques
- **Human-AI Interaction** - Trust, explainability, and user validation

## 1. Comprehensive RAI Surveys (2020-2025)

### Latest Comprehensive Surveys (2024-2025)
- [2025] **The 2025 AI Index Report** *Stanford HAI* [[report](https://hai.stanford.edu/ai-index/2025-ai-index-report)]
- [2024] **Recent Applications of Explainable AI (XAI): A Systematic Literature Review** *Applied Sciences* [[paper](https://www.mdpi.com/2076-3417/14/19/8884)]
- [2024] **Policy advice and best practices on bias and fairness in AI** *Ethics and Information Technology* [[paper](https://link.springer.com/article/10.1007/s10676-024-09746-w)]
- [2024] **Fairness and Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, and Mitigation Strategies** *Sci* [[paper](https://www.mdpi.com/2413-4155/6/1/3)]
- [2024] **AI Fairness in Data Management and Analytics: A Review on Challenges, Methodologies and Applications** *Applied Sciences* [[paper](https://www.mdpi.com/2076-3417/13/18/10258)]
- [2024] **Evaluating privacy, security, and trust perceptions in conversational AI: A systematic review** *A Leschanowsky, S Rech, B Popp, T B√§ckstr√∂m* [[paper](https://www.sciencedirect.com/science/article/pii/S0747563224002127)]
- [2024] **Fairness in Machine Learning: A Survey.** *Simon Caton and Christian Haas* [[paper](https://dl.acm.org/doi/10.1145/3616865)]
- [2024/10] **Responsible AI in the Global Context: Maturity Model and Survey** *Anka Reuel,Patrick Connolly* [[paper](https://arxiv.org/pdf/2410.09985)]
- [2024/4] **Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering** *Qinghua Lu, Liming Zhu* [[paper](https://dl.acm.org/doi/full/10.1145/3626234)]
- [2024] **Human-centered evaluation of explainable AI applications: a systematic review** *Frontiers in AI* [[paper](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1456486/full)]

### Foundational Surveys (2020-2023)
- [2023] **Explainable AI (XAI): A systematic meta-survey of current challenges and future opportunities** *Knowledge-Based Systems* [[paper](https://www.sciencedirect.com/science/article/pii/S0950705123000230)]
- [2023] **An Empirical Survey on Explainable AI Technologies: Recent Trends, Use-Cases, and Categories** *Electronics* [[paper](https://www.mdpi.com/2079-9292/12/5/1092)]
- [2023] **Survey on Explainable AI: From Approaches, Limitations and Applications Aspects** *Human-Centric Intelligent Systems* [[paper](https://link.springer.com/article/10.1007/s44230-023-00038-y)]
- [2023] **Explainable artificial intelligence: A survey of needs, techniques, applications, and future direction** *ScienceDirect* [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0925231224008828)]
- [2023] **AI governance: themes, knowledge gaps and future agendas** *Emerald Insight* [[paper](https://www.emerald.com/insight/content/doi/10.1108/intr-01-2022-0042/full/html)]
- [2022] **Privacy Governance Report** *IAPP* [[report](https://iapp.org/resources/article/privacy-governance-report/)]
- [2021] **A Survey on Bias and Fairness in Machine Learning** *arXiv* [[paper](http://arxiv.org/pdf/1908.09635)]
- [2021] **Explainable AI: A Review of Machine Learning Interpretability Methods** *Entropy* [[paper](https://www.mdpi.com/1099-4300/23/1/18)]
- [2020] **Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI** *Information Fusion* [[paper](https://www.sciencedirect.com/science/article/abs/pii/S1566253519308103)]

### Healthcare & Medical Applications
- [2024] **A survey of recent methods for addressing AI fairness and bias in biomedicine** *ScienceDirect* [[paper](https://www.sciencedirect.com/science/article/pii/S1532046424000649)]
- [2024] **Interpreting artificial intelligence models: a systematic review on the application of LIME and SHAP in Alzheimer's disease detection** *PMC* [[paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC10997568/)]
- [2024] **Ethical and Bias Considerations in Artificial Intelligence/Machine Learning** *ScienceDirect* [[paper](https://www.sciencedirect.com/science/article/pii/S0893395224002667)]
- [2024] **Fairness of artificial intelligence in healthcare: review and recommendations** *PMC* [[paper](https://pmc.ncbi.nlm.nih.gov/articles/PMC10764412/)]

### Ethics & Governance Focus
- [2024] **AI Governance in a Complex and Rapidly Changing Regulatory Landscape: A Global Perspective** *Nature* [[paper](https://www.nature.com/articles/s41599-024-03560-x)]
- [2023] **Ethics and discrimination in artificial intelligence-enabled recruitment practices** *Nature* [[paper](https://www.nature.com/articles/s41599-023-02079-x)]
- [2023] **AI Regulations: Prepare for More AI Rules on Privacy Rights, Data Protection, and Fairness** *TrustArc* [[analysis](https://trustarc.com/resource/ai-regulations-ai-rules-privacy-rights-data-protection/)]

## 2. Comprehensive RAI Papers (2020-2025)

### 2.1 Explainable AI & Interpretability

#### Recent Advances in XAI Methods (2024-2025)
- [2025] **A Perspective on Explainable Artificial Intelligence Methods: SHAP and LIME** *Advanced Intelligent Systems* [[paper](https://advanced.onlinelibrary.wiley.com/doi/full/10.1002/aisy.202400304)]
- [2025] **Explainable AI for Forensic Analysis: A Comparative Study of SHAP and LIME in Intrusion Detection Models** *MDPI Applied Sciences* [[paper](https://www.mdpi.com/2076-3417/15/13/7329)]
- [2025] **Fewer Than 1% of Explainable AI Papers Validate Explainability with Humans** *arXiv* [[paper](https://arxiv.org/html/2503.16507v1)]
- [2024] **Interpreting artificial intelligence models: a systematic review on the application of LIME and SHAP in Alzheimer's disease detection** *Brain Informatics* [[paper](https://braininformatics.springeropen.com/articles/10.1186/s40708-024-00222-1)]

#### Foundational XAI Works (2020-2023)
- [2023] **Explainable AI (XAI): A systematic meta-survey of current challenges and future opportunities** *Knowledge-Based Systems* [[paper](https://www.sciencedirect.com/science/article/pii/S0950705123000230)]
- [2023] **An Empirical Survey on Explainable AI Technologies: Recent Trends, Use-Cases, and Categories** *Electronics* [[paper](https://www.mdpi.com/2079-9292/12/5/1092)]
- [2021] **Explainable AI: A Review of Machine Learning Interpretability Methods** *Entropy* [[paper](https://www.mdpi.com/1099-4300/23/1/18)]
- [2020] **Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI** *Information Fusion* [[paper](https://www.sciencedirect.com/science/article/abs/pii/S1566253519308103)]

#### Continuing Core Methods
- **Focus! Rating XAI Methods and Finding Biases** *Anna Arias-Duart, Ferran Par√©s*[[paper](https://ieeexplore.ieee.org/abstract/document/9882821)]
- **A Review on Explainable Artificial Intelligence for Healthcare: Why, How, and When?** * Subrato Bharati, M. Rubaiyat Hossain Mondal*[[paper](https://arxiv.org/abs/2304.04780)]
- **Efficient data representation by selecting prototypes with importance weights** *Gurumoorthy, K. S., Dhurandhar*[[paper](https://arxiv.org/abs/1707.01212)]
- **TED: Teaching AI to explain its decisions** *Hind, M., Wei, D., Campbell*[[paper](https://doi.org/10.1145/3306618.3314273)]
- **A unified approach to interpreting model predictions** *Lundberg, S. M., & Lee*[[paper](https://github.com/slundberg/shap)]
- **Leveraging latent features for local explanations** *Luss, R., Chen, P. Y*[[paper](https://arxiv.org/abs/1905.12698)]
- **Contrastive Explanations Method with Monotonic Attribute Functions** *Luss et al*[[paper](https://arxiv.org/abs/1905.12698)]
- **Boolean Decision Rules via Column Generation** *Dash et al*[[paper](https://papers.nips.cc/paper/7716-boolean-decision-rules-via-column-generation)]
- **Explainable AI (XAI): Core ideas, techniques, and solutions** *R Dwivedi, D Dave*[[paper](https://dl.acm.org/doi/abs/10.1145/3561048)]

### 2.2 AI Ethics, Fairness & Bias Mitigation

#### Recent Ethical Frameworks & Guidelines (2024-2025)
- [2025] **AI Ethics: Integrating Transparency, Fairness, and Privacy in AI Development** *Taylor & Francis* [[paper](https://www.tandfonline.com/doi/full/10.1080/08839514.2025.2463722)]
- [2024] **Navigating algorithm bias in AI: ensuring fairness and trust in Africa** *Frontiers* [[paper](https://www.frontiersin.org/journals/research-metrics-and-analytics/articles/10.3389/frma.2024.1486600/full)]
- [2025] **Artificial intelligence bias auditing ‚Äì current approaches, challenges and lessons from practice** *Emerald Insight* [[paper](https://www.emerald.com/insight/content/doi/10.1108/raf-01-2025-0006/full/html)]
- [2024] **Policy advice and best practices on bias and fairness in AI** *Ethics and Information Technology* [[paper](https://link.springer.com/article/10.1007/s10676-024-09746-w)]

#### Foundational Bias & Fairness Research (2020-2023)
- [2023] **Ethics and discrimination in artificial intelligence-enabled recruitment practices** *Nature* [[paper](https://www.nature.com/articles/s41599-023-02079-x)]
- [2023] **AI Fairness in Data Management and Analytics: A Review on Challenges, Methodologies and Applications** *Applied Sciences* [[paper](https://www.mdpi.com/2076-3417/13/18/10258)]
- [2021] **A Survey on Bias and Fairness in Machine Learning** *ACM Computing Surveys* [[paper](http://arxiv.org/pdf/1908.09635)]
- [2020] **Sex and gender differences and biases in artificial intelligence for biomedicine and healthcare** *NPJ Digital Medicine* [[paper](https://www.nature.com/articles/s41746-020-0288-5)]

#### Bias Detection & Mitigation Techniques
- **Mitigating bias in artificial intelligence: Fair data generation via causal models for transparent and explainable decision-making** *ScienceDirect* [[paper](https://www.sciencedirect.com/science/article/pii/S0167739X24000694)]
- **Fairness through Experimentation: Inequality in A/B testing as an approach to responsible design** *Saint-Jacques, G., Sepehri, A., Li, N., & Perisic, I.* [[paper](https://arxiv.org/pdf/2002.05819)]
- **Socially Responsible AI Algorithms: Issues, Purposes, and Challenges** *L Cheng, KR Varshney*[[paper](https://www.jair.org/index.php/jair/article/view/12814)]
- **Fairness in Machine Learning: A Survey** *Simon Caton, Christian Haas*[[paper](https://dl.acm.org/doi/10.1145/3616865)]

### 2.3 AI Governance & Regulatory Frameworks

#### Major Regulatory Developments (2024-2025)
- [2024] **EU AI Act Implementation** *European Commission* [[official](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai)]
- [2024] **NIST AI Risk Management Framework Updates** *NIST* [[framework](https://www.nist.gov/itl/ai-risk-management-framework)]
- [2025] **Use ISO 42001 & NIST AI RMF to Help with the EU AI Act** *CSA* [[guide](https://cloudsecurityalliance.org/blog/2025/01/29/how-can-iso-iec-42001-nist-ai-rmf-help-comply-with-the-eu-ai-act)]
- [2024] **AI governance trends: How regulation, collaboration, and skills demand are shaping the industry** *World Economic Forum* [[analysis](https://www.weforum.org/stories/2024/09/ai-governance-trends-to-watch/)]

#### Foundational Governance Research (2020-2023)
- [2023] **AI governance: themes, knowledge gaps and future agendas** *Emerald Insight* [[paper](https://www.emerald.com/insight/content/doi/10.1108/intr-01-2022-0042/full/html)]
- [2023] **AI Regulations: Prepare for More AI Rules on Privacy Rights, Data Protection, and Fairness** *TrustArc* [[analysis](https://trustarc.com/resource/ai-regulations-ai-rules-privacy-rights-data-protection/)]
- [2022] **OECD AI Principles and Privacy Guidelines** *OECD* [[report](https://www.oecd.org/en/publications/ai-data-governance-and-privacy_2476b1a4-en.html)]
- [2021] **The Blueprint for an AI Bill of Rights** *White House* [[framework](https://www.whitehouse.gov/ostp/ai-bill-of-rights/)]

#### Comparative Regulatory Analysis
- [2024] **The EU and U.S. diverge on AI regulation: A transatlantic comparison and steps to alignment** *Brookings* [[analysis](https://www.brookings.edu/articles/the-eu-and-us-diverge-on-ai-regulation-a-transatlantic-comparison-and-steps-to-alignment/)]
- [2025] **Navigating AI Compliance: An Integrated Approach to the NIST AI RMF & EU AI Act** *Securiti* [[whitepaper](https://securiti.ai/whitepapers/an-approach-to-nist-ai-rmf-and-eu-ai-act/)]
- [2024] **AI Governance in a Complex and Rapidly Changing Regulatory Landscape: A Global Perspective** *Nature* [[paper](https://www.nature.com/articles/s41599-024-03560-x)]

### 2.4 Environmental Sustainability & Green AI

#### Carbon Footprint & Environmental Impact Studies (2024-2025)
- [2024] **The Climate and Sustainability Implications of Generative AI** *MIT Climate & Sustainability Consortium* [[paper](https://impactclimate.mit.edu/2024/04/10/considering-the-environmental-impacts-of-generative-ai-to-spark-responsible-development/)]
- [2025] **Explained: Generative AI's environmental impact** *MIT News* [[article](https://news.mit.edu/2025/explained-generative-ai-environmental-impact-0117)]
- [2025] **Environmental Impact of Generative AI | Stats & Facts for 2025** *The Sustainable Agency* [[report](https://thesustainableagency.com/blog/environmental-impact-of-generative-ai/)]
- [2024] **Impacts of generative AI on sustainability** *PwC* [[analysis](https://www.pwc.com/us/en/tech-effect/emerging-tech/impacts-of-generative-ai-on-sustainability.html)]
- [2024] **AI brings soaring emissions for Google and Microsoft, a major contributor to climate change** *NPR* [[report](https://www.npr.org/2024/07/12/g-s1-9545/ai-brings-soaring-emissions-for-google-and-microsoft-a-major-contributor-to-climate-change)]

#### Foundational Environmental Research (2020-2023)
- [2023] **Energy and policy considerations for deep learning in NLP** *Strubell, E., Ganesh, A., & McCallum, A.* [[paper](https://arxiv.org/abs/1906.02243)]
- [2022] **Sustainable AI: Environmental implications, challenges, and opportunities** *Wu, C.-J., et al.* [[paper](https://proceedings.mlsys.org/paper_files/paper/2022/file/462211f67c7d858f663355eff93b745e-Paper.pdf)]
- [2021] **Sustainable AI: AI for sustainability and the sustainability of AI** *van Wynsberghe, A.* [[paper](https://link.springer.com/article/10.1007/s10676-021-00043-6)]
- [2021] **Carbon emissions and large neural network training** *Patterson, D., et al.* [[paper](https://arxiv.org/abs/2104.10350)]
- [2020] **Green Algorithms: Quantifying the carbon emissions of computation** *Lannelongue, L. et al.* [[paper](https://arxiv.org/abs/2007.07610)]

#### Sustainable AI Practices
- **Making AI Less "Thirsty": Uncovering and Addressing the Secret Water Footprint of AI Models** *Li, P., Yang, J., Islam, M. A., & Ren, S.* [[paper](https://arxiv.org/pdf/2304.03271)]
- **The energy and carbon footprint of training end-to-end speech recognizers** *Parcollet, T., & Ravanelli, M.* [[paper](https://hal.archives-ouvertes.fr/hal-03190119/document)]
- **Quantifying the carbon emissions of machine learning** *Lacoste, A., et al.* [[paper](https://arxiv.org/abs/1910.09700)]

### 2.5 Privacy & Security in AI

#### Latest Privacy Frameworks (2024-2025)
- [2024-2025] **AI and Privacy: Shifting from 2024 to 2025** *CSA* [[analysis](https://cloudsecurityalliance.org/blog/2025/04/22/ai-and-privacy-2024-to-2025-embracing-the-future-of-global-legal-developments)]
- [2024] **Privacy Governance Report** *IAPP* [[report](https://iapp.org/resources/article/privacy-governance-report/)]
- [2023] **Ted-spad: Temporal distinctiveness for self-supervised privacy-preservation for video anomaly detection** *J Fioresi, IR Dave, M Shah* [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.html)]

#### Foundational Privacy Research (2020-2023)
- [2022] **Data cards: Purposeful and transparent dataset documentation for responsible AI** *Pushkarna, M., Zaldivar, A., & Kjartansson, O.* [[paper](https://dl.acm.org/doi/10.1145/3531146.3533231)]
- [2022] **Healthsheet: Development of a transparency artifact for health datasets** *Rostamzadeh, N., et al.* [[paper](https://arxiv.org/abs/2202.13028)]
- [2020] **Privacy-Preserving Machine Learning** [[book](https://www.manning.com/books/privacy-preserving-machine-learning)]

#### Security & Adversarial AI
- [2024] **Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations** *NIST* [[paper](https://www.nist.gov/publications/adversarial-machine-learning-taxonomy-and-terminology-attacks-and-mitigations)]
- [2024] **EU AI Act, US NIST Target Cyberattacks on AI Systems** *Morgan Lewis* [[analysis](https://www.morganlewis.com/pubs/2024/07/eu-ai-act-us-nist-target-cyberattacks-on-ai-systems-guidance-and-reporting-obligations)]

### 2.6 Advanced Models & Foundation Model Governance

#### Foundation Model Transparency & Evaluation (2023-2025)
- [2024] **FAIR Enough: Develop and Assess a FAIR-Compliant Dataset for Large Language Model Training?** *S Raza, et al.* [[paper](https://direct.mit.edu/dint/article/6/2/559/123375)]  
- [2024] **Exploring Memorization and Copyright Violation in Frontier LLMs: A Study of the New York Times v. OpenAI 2023 Lawsuit** *J Freeman, et al.* [[paper](https://openreview.net/forum?id=C66DBl9At8)]

#### Generative AI Governance
- [2024] **Generative AI in Creative Practice: ML-Artist Folk Theories of T2I Use, Harm, and Harm-Reduction** *Renee Shelby, et al.* [[paper](https://dl.acm.org/doi/full/10.1145/3613904.3642461)]
- [2024] **Evolving Generative AI: Entangling the Accountability Relationship** *Marc T.J Elliott, Deepak P* [[paper](https://dl.acm.org/doi/abs/10.1145/3664823)]
- [2024] **Ethical Challenges and Solutions of Generative AI: An Interdisciplinary Perspective** *Mousa Al-kfairy, Dheya Mustafa* [[paper](https://arxiv.org/pdf/2410.09985)]

### 2.7 Technical Debt & System Reliability

#### ML Systems Engineering (2015-2023)
- [2022] **Sustainable AI: Environmental implications, challenges, and opportunities** *Wu, C.-J., et al.* [[paper](https://proceedings.mlsys.org/paper_files/paper/2022/file/462211f67c7d858f663355eff93b745e-Paper.pdf)]
- [2020] **Machine learning: The high interest credit card of technical debt** *Sculley, D., et al.* [[paper](https://research.google/pubs/pub43146/)]
- [2015] **Hidden technical debt in machine learning systems** *Sculley, D., et al.* [[paper](https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)]

### 2.8 Industry Reports & Practical Implementation

#### Latest Industry Surveys (2024-2025)
- [2024] **PwC's 2024 US Responsible AI Survey** *PwC* [[report](https://www.pwc.com/us/en/tech-effect/ai-analytics/responsible-ai-survey.html)]
- [2025] **The State of AI: Global survey** *McKinsey* [[survey](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai)]
- [2025] **Responsible AI Revisited: Critical Changes and Updates Since Our 2023 Playbook** *Adnan Masood* [[analysis](https://medium.com/@adnanmasood/responsible-ai-revisited-critical-changes-and-updates-since-our-2023-playbook-0c1610d57f37)]

#### Foundational Industry Guidance (2020-2023)
- [2023] **Responsible AI (RAI) Games and Ensembles** *Yash Gupta, et al.* [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/e6057bf047bcc5f86ebf4e8db6e24a1f-Abstract-Conference.html)]
- [2022] **Toward Responsible Artificial Intelligence in Long-Term Care: A Scoping Review on Practical Approaches** *Dirk R M Lukkien, et al.* [[paper](https://academic.oup.com/gerontologist/article/63/1/155/6454353)]

### 2.9 Advanced Reasoning & Interpretability Techniques

#### Recent Advances in AI Reasoning (2022-2024)
- [2024] **Graph of Thoughts: Solving Elaborate Problems with Large Language Models** *arXiv* [[paper](summaries/explainability/GoT.md)]
- [2024] **Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation** *ICML* [[paper](summaries/explainability/LLM_random_walk.md)]
- [2024] **Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models** *ICML* [[paper](summaries/explainability/Patchscopes.md)]
- [2023] **Tree of Thoughts: Deliberate Problem Solving with Large Language Models** *NeurIPS* [[paper](summaries/explainability/ToT.md)]
- [2023] **Sparse Autoencoders Find Highly Interpretable Features in Language Models** *arXiv* [[paper](summaries/explainability/SAE-interpret.md)]
- [2022] **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models** *NeurIPS* [[paper](summaries/explainability/CoT.md)]

#### Knowledge Representation & Structured Explanations
- [2021] **A Survey on Knowledge Graphs: Representation, Acquisition, and Applications** *IEEE TNNLS* [[paper](summaries/explainability/knowlege_graphs_survey.md)]
- [2018] **A Nutritional Label for Rankings** *SIGMOD* [[paper](summaries/explainability/Nutritional_Label.md)]

### 2.10 Human-AI Interaction & Trust

#### Human-Centered AI Research (2020-2024)
- [2024] **Human-centered evaluation of explainable AI applications: a systematic review** *Frontiers in AI* [[paper](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1456486/full)]
- [2025] **Fewer Than 1% of Explainable AI Papers Validate Explainability with Humans** *arXiv* [[paper](https://arxiv.org/html/2503.16507v1)]
- [2022] **Human-In-The-Loop Machine Learning: Active Learning and Annotation for Human-Centered AI** [[book](https://www.manning.com/books/human-in-the-loop-machine-learning)]
- [2021] **Trust in Machine Learning** *Varshney, K.* [[book](https://www.manning.com/books/trust-in-machine-learning)]
- [2020] **Interpretable AI** *Thampi, A.* [[book](https://www.manning.com/books/interpretable-ai)]

#### Trust and Explainability Frameworks
- [2022] **Interpretable Machine Learning With Python: Learn to Build Interpretable High-Performance Models** [[book](https://www.packtpub.com/product/interpretable-machine-learning-with-python/9781800203907)]
- [2021] **AI Fairness** *Mahoney, T., Varshney, K.R., Hind, M.* [[book](https://learning.oreilly.com/library/view/ai-fairness/9781492077664/)]
- [2021] **Practical Fairness** *Nielsen, A.* [[book](https://learning.oreilly.com/library/view/practical-fairness/9781492075721/)]
- [2020] **Hands-On Explainable AI (XAI) with Python** *Rothman, D.* [[book](https://www.packtpub.com/product/hands-on-explainable-ai-xai-with-python/9781800208131)]
- [2020] **Responsible Machine Learning** *Hall, P., Gill, N., Cox, B.* [[book](https://learning.oreilly.com/library/view/responsible-machine-learning/9781492090878/)]

### 2.11 Legal & Regulatory Compliance

#### Legal Frameworks & Compliance (2020-2025)
- [2024] **AI and the Law** *Kilroy, K.* [[book](https://learning.oreilly.com/library/view/ai-and-the/9781492091837/)]
- [2024] **Responsible AI** *Hall, P., Chowdhury, R.* [[book](https://learning.oreilly.com/library/view/responsible-ai/9781098102425/)]
- [2023] **The Chinese approach to artificial intelligence: An analysis of policy, ethics, and regulation** *Roberts, H., et al.* [[paper](https://link.springer.com/article/10.1007/s00146-020-00992-2)]
- [2022] **NIST Special Publication: Towards a Standard for Identifying and Managing Bias in Artificial Intelligence** *Schwartz, R., et al.* [[report](https://www.nist.gov/publications/towards-standard-identifying-and-managing-bias-artificial-intelligence)]

#### International Standards & Guidelines
- [2024] **ISO/IEC 42001:2023 - Artificial Intelligence Management Systems** [[standard](https://www.iso.org/standard/81230.html)]
- [2023] **UNESCO Recommendation on the Ethics of Artificial Intelligence** [[framework](https://www.unesco.org/en/articles/recommendation-ethics-artificial-intelligence)]
- [2021] **OECD AI Principles** [[principles](https://www.oecd.org/going-digital/ai/principles/)]
- [2019] **Ethics Guidelines for Trustworthy AI** *European Commission* [[guidelines](https://op.europa.eu/en/publication-detail/-/publication/d3988569-0434-11ea-8c1f-01aa75ed71a1)]

## 3. Datasets & Resources

### Latest AI Safety & Governance Datasets
- **AI Risk Database** [[Link](https://airisk.io/)] 
- **AI Risk Repository** [[Link](https://airisk.mit.edu)] 
- **ARC AGI** [[Link](https://github.com/fchollet/ARC-AGI)]
- **Common Corpus** [[Link](https://huggingface.co/collections/PleIAs/common-corpus-65d46e3ea3980fdcd66a5613)]
- **An ImageNet replacement for self-supervised pretraining without humans** [[Link](https://www.robots.ox.ac.uk/~vgg/research/pass/)]
- **Huggingface Data Sets** [[Link](https://huggingface.co/datasets)]
- **The Stack** [[Link](https://www.bigcode-project.org/docs/about/the-stack/)]

### Evaluation Frameworks Evolution (2020-2025)
- **Foundation Model Transparency Index** - Updated May 2024 with average transparency scores increasing from 37% to 58%
- **Hughes Hallucination Evaluation Model** - Updated leaderboard for factuality assessment
- **FACTS** - New comprehensive evaluation framework (2024)
- **SimpleQA** - Recently introduced for straightforward AI evaluation (2024)
- **HELM Safety** - New benchmark for safety assessment (2024)
- **AIR-Bench** - Latest responsible AI benchmarking tool (2024)
- **HaluEval** - Earlier benchmark for truthfulness evaluation (2022)
- **TruthfulQA** - Foundational truthfulness assessment (2021)

## 4. Applications by Sector

### üìö Education
- **AI literacy and responsible deployment** in educational institutions
- **Student data privacy** and algorithmic bias in educational AI tools
- **Automated grading systems** and fairness considerations
- **Personalized learning algorithms** and equity concerns

### üåç Environmental Sustainability
- **Carbon footprint assessment** and mitigation strategies for AI systems
- **Green AI practices** and renewable energy integration
- **Water consumption optimization** in data centers
- **Lifecycle environmental impact** of AI hardware and software

### üë• Society
- **Algorithm bias in African contexts** and developing nations
- **Digital divide** and equitable AI access
- **Social justice implications** of AI deployment
- **Community engagement** in AI governance decisions

### ‚öñÔ∏è Politics & Governance
- **AI-related election misinformation** across 10+ countries and social media platforms
- **Democratic governance** of AI systems
- **International cooperation** on AI standards
- **Public policy development** for AI regulation

### ü©∫ Healthcare
- **Clinical decision support system** transparency
- **Medical AI bias detection** and mitigation
- **Patient data privacy** in AI-powered diagnostics
- **FDA approval processes** for AI-enabled medical devices (223 approvals in 2023, up from 6 in 2015)

### üí∞ Finance
- **Algorithmic auditing** in financial services
- **Fair lending practices** and bias prevention
- **Regulatory compliance** for financial AI
- **Credit scoring fairness** and transparency

### üõ°Ô∏è Defense
- **Ethical considerations** in military AI applications
- **Autonomous weapons governance**
- **National security AI frameworks**
- **International humanitarian law** and AI warfare

### üé® Arts and Entertainment
- **Copyright and intellectual property** in generative AI
- **Creative AI ethics** and artist rights
- **Deepfake detection** and media authenticity
- **Fair compensation** for creative content used in AI training

## 5. Detailed Evolution Timeline (2020-2025)

### 2020: Foundation Year
**Key Developments:**
- Publication of seminal XAI survey by Arrieta et al. establishing foundational concepts
- Early COVID-19 pandemic accelerating AI adoption in healthcare
- Growing awareness of algorithmic bias in hiring and criminal justice systems
- Initial privacy frameworks addressing AI-specific concerns

**Major Papers:**
- Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI
- Sex and gender differences and biases in artificial intelligence for biomedicine and healthcare
- Early work on privacy-preserving machine learning techniques

### 2021: Regulatory Awakening
**Key Developments:**
- EU proposes first comprehensive AI regulation (AI Act draft)
- White House releases Blueprint for an AI Bill of Rights
- Increased focus on machine learning interpretability methods
- Growing industry awareness of technical debt in ML systems

**Major Papers:**
- Explainable AI: A Review of Machine Learning Interpretability Methods
- A Survey on Bias and Fairness in Machine Learning
- Trust in Machine Learning frameworks
- Sustainable AI: AI for sustainability and the sustainability of AI

### 2022: Framework Consolidation
**Key Developments:**
- NIST releases AI Risk Management Framework (draft)
- Chain-of-Thought prompting revolutionizes LLM reasoning
- Privacy governance reports highlight organizational challenges
- Increased focus on data governance and documentation

**Major Papers:**
- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
- Data cards: Purposeful and transparent dataset documentation for responsible AI
- Sustainable AI: Environmental implications, challenges, and opportunities
- Privacy Governance Report documenting organizational practices

### 2023: Generative AI Revolution
**Key Developments:**
- ChatGPT launch triggers global AI governance discussions
- Systematic reviews of XAI methods proliferate
- Ethics in AI-enabled recruitment becomes major concern
- Tree of Thoughts and advanced reasoning methods emerge

**Major Papers:**
- Explainable AI (XAI): A systematic meta-survey of current challenges and future opportunities
- Ethics and discrimination in artificial intelligence-enabled recruitment practices
- Tree of Thoughts: Deliberate Problem Solving with Large Language Models
- AI governance: themes, knowledge gaps and future agendas

### 2024: Regulatory Implementation
**Key Developments:**
- EU AI Act enters into force (August 1, 2024)
- Major tech companies report significant emission increases due to AI
- 28.8% increase in RAI papers at leading AI conferences
- Foundation Model Transparency Index shows improvement from 37% to 58%

**Major Papers:**
- Recent Applications of Explainable AI (XAI): A Systematic Literature Review
- The Climate and Sustainability Implications of Generative AI
- AI Governance in a Complex and Rapidly Changing Regulatory Landscape
- Policy advice and best practices on bias and fairness in AI

### 2025: Maturation and Standards
**Key Developments:**
- 78% of organizations now use AI in at least one business function
- Environmental concerns intensify with GPU shipments reaching 3.85 million
- Human validation of XAI methods remains critically low (<1%)
- ISO standards for sustainable AI expected

**Major Papers:**
- The 2025 AI Index Report
- A Perspective on Explainable Artificial Intelligence Methods: SHAP and LIME
- Fewer Than 1% of Explainable AI Papers Validate Explainability with Humans
- Environmental Impact of Generative AI: Latest statistics and mitigation strategies

## 6. Key Takeaways for 2020-2025 Evolution

### Critical Developments Across the Period:

#### 2020-2021: Foundation and Awareness
1. **Conceptual Foundations**: Establishment of core XAI taxonomies and ethical frameworks
2. **Early Regulatory Signals**: EU AI Act proposal and White House AI Bill of Rights
3. **Healthcare Focus**: COVID-19 pandemic accelerating AI adoption with fairness concerns
4. **Technical Debt Recognition**: Growing awareness of ML system maintenance challenges

#### 2022-2023: Framework Development and GenAI Emergence
1. **Methodological Advances**: Chain-of-Thought prompting and advanced reasoning techniques
2. **Governance Frameworks**: NIST AI RMF and comprehensive governance models
3. **GenAI Revolution**: ChatGPT launch transforming responsible AI discussions
4. **Systematic Reviews**: Proliferation of comprehensive surveys and meta-analyses

#### 2024-2025: Implementation and Maturation
1. **Regulatory Reality**: EU AI Act implementation marking shift to mandatory compliance
2. **Environmental Crisis**: Major tech companies reporting 29-48% emissions increases due to AI workloads
3. **Industry Adoption**: 78% of organizations now using AI, up from 55% in early 2023
4. **Research Growth**: Nearly 30% increase in responsible AI research publications

### Persistent Challenges Throughout 2020-2025:
- **Human Validation Gap**: Fewer than 1% of XAI papers validate explainability with humans
- **Standardization Deficit**: Lack of standardized RAI evaluations among major AI developers
- **Environmental Impact**: Exponential growth in computational demands and carbon emissions
- **Bias Persistence**: Continued algorithmic discrimination across domains despite mitigation efforts

### Emerging Solutions and Trends:
- **Technical Innovation**: Advanced reasoning methods (CoT, ToT, Graph of Thoughts)
- **Regulatory Harmonization**: International cooperation on AI governance standards
- **Industry Maturation**: Shift from voluntary guidelines to mandatory compliance frameworks
- **Environmental Awareness**: Growing focus on sustainable AI and green computing practices

## 7. Future Research Directions

### Priority Areas for Continued Research:

#### Technical Innovations Needed:
1. **Human-Validated XAI**: Methods that demonstrably improve human understanding and decision-making
2. **Energy-Efficient AI**: Algorithms and architectures that dramatically reduce computational requirements
3. **Robust Bias Detection**: Automated systems for identifying and mitigating algorithmic discrimination
4. **Federated Governance**: Distributed approaches to AI oversight and compliance

#### Policy and Governance Gaps:
1. **Global Standards Harmonization**: Unified international frameworks for AI governance
2. **Real-time Compliance Monitoring**: Automated systems for regulatory adherence
3. **Cross-jurisdictional Enforcement**: Mechanisms for managing global AI deployment
4. **Stakeholder Engagement**: Inclusive processes for affected community participation

#### Societal Integration Challenges:
1. **Digital Divide**: Ensuring equitable access to responsible AI benefits
2. **Cultural Adaptation**: Contextualizing AI ethics for diverse global communities
3. **Intergenerational Impact**: Long-term consequences of AI deployment decisions
4. **Democratic Participation**: Public involvement in AI governance decisions

## 8. Contributing Authors
- SHAINA RAZA‚àó, Vector Institute, Canada
- RIZWAN QURESHI‚àó, Center for Research in Computer Vision, The University of Central Florida, USA
- ANAM ZAHID, Department of Computer Science, Information Technology University of the Punjab, Pakistan
- SAFIULLAH KAMAWAL, Queen‚Äôs University, Vector Institute, Canada
- JOE FIORESI, Center for Research in Computer Vision, The University of Central Florida, USA
- FERHAT SADAK, Department of Mechanical Engineering, Bartin University, T√ºrkiye
- MUHAMMAED SAEED, Saarland University, Germany
- RANJAN SAPKOTA, Washington State University, USA
- ADITYA JAIN, University of Texas at Austin, USA
- ANAS ZAFAR, Fast School of Computing, National University of Computer and Emerging Sciences, Pakistan
- MUNEEB UL HASSAN, School of Information Technology, Deakin University, Australia
- AIZAN ZAFAR, Center for research in computer vision, University of Central FLorida, USA
- HASAN MAQBOOL, Independent Researcher, USA
- ASHMAL VAYANI, Center for Research in Computer Vision, University of Central Florida, USA
- JIA WU, MD Anderson Cancer Center, The University of Texas, USA
- MAGED SHOMAN, University of Tennessee; Oak Ridge National Lab, USA

*Equal contributors

## üìù Citation

If you find our survey useful for your research, please cite the following paper:

```bibtex
@article{raza2025responsible,
  title        = {Who is Responsible? The Data, Models, Users or Regulations? Responsible Generative AI for a Sustainable Future},
  author       = {Shaina Raza and Rizwan Qureshi and Anam Zahid and Joseph Fioresi and Ferhat Sadak and Muhammad Saeed and Ranjan Sapkota and Aditya Jain and Anas Zafar and Muneeb Ul Hassan and Aizan Zafar and Hasan Maqbool and Ashmal Vayani and Jia Wu and Maged Shoman},
  journal      = {TechRxiv Preprints},
  year         = {2025},
  publisher    = {TechRxiv},
  doi          = {10.36227/techrxiv.173834932.29831105},
  url          = {https://www.techrxiv.org/doi/full/10.36227/techrxiv.173834932.29831105/v1}
}
```

---

**Last Updated**: July 2025  
